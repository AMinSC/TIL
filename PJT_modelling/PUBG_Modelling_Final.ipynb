{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306c5e6f",
   "metadata": {},
   "source": [
    "## PUBG Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee5ad7",
   "metadata": {},
   "source": [
    "플레이어들이 전장에서 벌이는 모든 행위를 분류하여 승리를 예측하기 위한 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe999b5",
   "metadata": {},
   "source": [
    "## Column 별 정보\n",
    "- ASSISTS : 자신에 의해 사살되지는 못했지만 자신의 데미지 지분율이 가장 높은 적의 수\n",
    "- BOOSTS : 도핑 아이템 사용 횟수(에너지 드링크, 진통제, 아드레날린 주사기)\n",
    "- DAMAGEDEALT : 적에게 가한 전체 데미지\n",
    "- DBNOS : 기절시킨 적의 수\n",
    "- GROUPID : 경기 내 그룹 식별 ID\n",
    "- HEADSHOTKILLS : 헤드샷으로 죽인 적의 수\n",
    "- HEALS : 회복 아이템 사용 횟수(붕대, 구급상자, 의료용 키트)\n",
    "- ID : 해당 데이터 ID\n",
    "- KILLPLACE : 경기 내 적을 죽인 적 수의 순위\n",
    "- KILLPOINTS : 유저의 ELO레이팅(죽인 적 수 기반)\n",
    "- KILLS : 경기 내 적을 죽인 수\n",
    "- KILLSTREAKS : 짧은 시간 내에 연속으로 적을 죽인 수\n",
    "- LONGESTKILL : 사살한 적까지의 거리의 최대값\n",
    "- MATCHDURATION : 경기가 진행된 시간(단위:초)\n",
    "- MATCHID : 경기 식별 ID\n",
    "- MATCHTYPE : 경기 모드( ex: 솔로, 듀오, 스쿼드 )\n",
    "- MAXPLACE : 경기 내 총 인원 수\n",
    "- NUMGROUP : 경기 내 실제 참여 인원 수\n",
    "- RANKPOINTS : 유저의 ELO 레이팅\n",
    "- REVIVES : 유저가 팀원을 부활시킨 횟수\n",
    "- RIDEDISTANCE : 이동수단을 통해 이동한 거리(단위:m)\n",
    "- ROADKILLS : 이동수단으로 살해한 적의 수\n",
    "- SWIMDISTANCE : 수영으로 이동한 거리(단위:m)\n",
    "- TEAMKILLS : 같은 팀원을 살해한 수\n",
    "- VEHICLEDESTROYS : 파괴한 이동수단의 수\n",
    "- WALKDISTANCE : 도보로 이동한 거리(단위:m)\n",
    "- WEAPONSACQUIRED : 획득한 무기의 수\n",
    "- WINPOINTS : 유저의 ELO 레이팅(승리 횟수 기반)\n",
    "- WINPLACEPERC : 현재 경기에서의 백분위 기반 유저의 순위(종속변수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b23222",
   "metadata": {},
   "source": [
    "## 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20c27c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:30.871669Z",
     "start_time": "2022-06-16T00:41:26.984091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krc/miniforge3/envs/ml-modeling/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['custfunc.py', 'featuring.py', '.DS_Store', 'modelling.py', '__pycache__', '.ipynb_checkpoints', 'processing.py', 'PUBG_Modelling_Final.ipynb', 'main.py', 'data', 'catboost_info']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krc/miniforge3/envs/ml-modeling/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 학습을 위한 라이브러리 세팅\n",
    "from sklearn.linear_model import LinearRegression   \n",
    "from sklearn.linear_model import Lasso              \n",
    "from sklearn.linear_model import Ridge             \n",
    "from xgboost.sklearn import XGBRegressor            \n",
    "from lightgbm.sklearn import LGBMRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm.sklearn import LGBMClassifier        \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "\n",
    "# VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Hyper parameter tuning\n",
    "import optuna\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# others \n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "print(os.listdir(\"/Users/krc/TIL/PJT_modelling\"))\n",
    "import warnings                      \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0da92ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.212310Z",
     "start_time": "2022-06-16T00:41:30.873136Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/krc/TIL/PJT_modelling/data/train_V2.csv')\n",
    "\n",
    "test = pd.read_csv('/Users/krc/TIL/PJT_modelling/data/test_V2.csv')\n",
    "\n",
    "submission = pd.read_csv('/Users/krc/TIL/PJT_modelling/data/sample_submission_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42af9a",
   "metadata": {},
   "source": [
    "## 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc053ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.221672Z",
     "start_time": "2022-06-16T00:41:45.214092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "#     start_mem = df.memory_usage().sum() / 1024**2\n",
    "#     print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "#     end_mem = df.memory_usage().sum() / 1024**2\n",
    "#     print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "#     print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814d7cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.225553Z",
     "start_time": "2022-06-16T00:41:45.222721Z"
    }
   },
   "outputs": [],
   "source": [
    "def sorted_corr(data, column) :\n",
    "    df_corr = data.corr()\n",
    "    df_corr = df_corr.apply(lambda x: round(x ,2))\n",
    "    df_corr = df_corr.unstack()\n",
    "    df_corr = pd.DataFrame(df_corr[column][df_corr[column]<1].sort_values(ascending=False), columns=['Correlation'])\n",
    "    df_corr = df_corr.style.background_gradient(cmap='coolwarm_r')\n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f03b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.229809Z",
     "start_time": "2022-06-16T00:41:45.227466Z"
    }
   },
   "outputs": [],
   "source": [
    "def toVIF(features): \n",
    "    return pd.DataFrame({\n",
    "        \"feature\": features.columns,\n",
    "        \"VIF\": [variance_inflation_factor(features.values, idx)\n",
    "                for idx in range(features.shape[1])]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a68f82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.233518Z",
     "start_time": "2022-06-16T00:41:45.231068Z"
    }
   },
   "outputs": [],
   "source": [
    "def OLS_summary(features, target):\n",
    "    sm_feature = sm.add_constant(features)\n",
    "    model = sm.OLS(target, sm_feature).fit()\n",
    "    print(model.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e0b956f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.242025Z",
     "start_time": "2022-06-16T00:41:45.235011Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression   # 1. Linear Regression\n",
    "from sklearn.linear_model import Lasso              # 2. Lasso\n",
    "from sklearn.linear_model import Ridge              # 3. Ridge\n",
    "from xgboost.sklearn import XGBRegressor            # 4. XGBoost\n",
    "from lightgbm.sklearn import LGBMRegressor          # 5. LightGBM\n",
    "from catboost import CatBoostRegressor              # 6. Catboost / SVR = X\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def Linear_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model = LinearRegression().fit(train_X, train_y)\n",
    "    pred_train = model.predict(train_X)\n",
    "    pred_val = model.predict(val_X)\n",
    "    mae_train = mean_absolute_error(train_y, pred_train)\n",
    "    mae_val = mean_absolute_error(val_y, pred_val)\n",
    "    return print(\"Linear Regression\\t train=%.4f, val=%.4f\" % (mae_train, mae_val))\n",
    "def Lasso_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model2 = Lasso().fit(train_X,train_y)\n",
    "    pred_train2 = model2.predict(train_X)\n",
    "    pred_val2 = model2.predict(val_X)\n",
    "    mae_train2 = mean_absolute_error(train_y, pred_train2)\n",
    "    mae_val2 = mean_absolute_error(val_y, pred_val2)\n",
    "    return print(\"Lasso\\t\\t train=%.4f, val=%4.f\" % (mae_train2, mae_val2))\n",
    "def Ridge_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model3 = Ridge().fit(train_X,train_y)\n",
    "    pred_train3 = model3.predict(train_X)\n",
    "    pred_val3 = model3.predict(val_X)\n",
    "    mae_train3 = mean_absolute_error(train_y, pred_train3)\n",
    "    mae_val3 = mean_absolute_error(val_y, pred_val3)\n",
    "    return print(\"Ridge\\t\\t train=%.4f, val=%.4f\" % (mae_train3, mae_val3))\n",
    "def XGB_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model4 = XGBRegressor().fit(train_X, train_y)\n",
    "    pred_train4 = model4.predict(train_X)\n",
    "    pred_val4 = model4.predict(val_X)\n",
    "    mae_train4 = mean_absolute_error(train_y, pred_train4)\n",
    "    mae_val4 = mean_absolute_error(val_y, pred_val4)\n",
    "    return print(\"XGBoost\\t\\t train=%.4f, val=%.4f\" % (mae_train4, mae_val4))\n",
    "def LGBM_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model5 = LGBMRegressor().fit(train_X, train_y)\n",
    "    pred_train5 = model5.predict(train_X)\n",
    "    pred_val5 = model5.predict(val_X)\n",
    "    mae_train5 = mean_absolute_error(train_y, pred_train5)\n",
    "    mae_val5 = mean_absolute_error(val_y, pred_val5)\n",
    "    return print(\"LightGBM\\t\\t train=%.4f, val=%.4f\" % (mae_train5, mae_val5))\n",
    "def CB_training_mae(target, features):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "    model6 = CatBoostRegressor(iterations=40, depth=16, learning_rate=1, loss_function='MAE').fit(train_X, train_y)\n",
    "    pred_train6 = model6.predict(train_X)\n",
    "    pred_val6 = model6.predict(val_X)\n",
    "    mae_train6 = mean_absolute_error(train_y, pred_train6)\n",
    "    mae_val6 = mean_absolute_error(val_y, pred_val6)\n",
    "    return print(\"CatBoost Regression \\t\\t train=%.4f, val=%.4f\" % (mae_train6, mae_val6))\n",
    "\n",
    "    \n",
    "def AllModels_mae(target, features):\n",
    "    print(\"Linaer training..\")\n",
    "    Linear = Linear_training_mae(target, features)\n",
    "    print(\"Lasso training..\")\n",
    "    Lasso = Lasso_training_mae(target, features)\n",
    "    print(\"Ridge training..\")\n",
    "    Ridge = Ridge_training_mae(target, features)\n",
    "    print(\"XGBoost training..\")\n",
    "    XGB = XGB_training_mae(target, features)\n",
    "    print(\"LightGBM training..\")\n",
    "    LGBM = LGBM_training_mae(target, features)\n",
    "    print(\"CatBoost training..\")\n",
    "    CB = CB_training_mae(target, features)\n",
    "    # return Linear, Lasso, Ridge, XGB, LGBM, CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727ceaae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.245274Z",
     "start_time": "2022-06-16T00:41:45.243117Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    train_OHE = pd.get_dummies(data, columns=[\"matchType\"])\n",
    "    train_OHE = reduce_mem_usage(train_OHE)\n",
    "    return train_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff384cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.249653Z",
     "start_time": "2022-06-16T00:41:45.246501Z"
    }
   },
   "outputs": [],
   "source": [
    "def ordinal_encoding(data):\n",
    "    train_OE = data.copy()\n",
    "    train_OE['matchType'] = train_OE['matchType'].map({\n",
    "        'solo':1,\n",
    "        'solo-fpp':2,\n",
    "        'duo':3,\n",
    "        'duo-fpp':4,\n",
    "        'squad':5,\n",
    "        'squad-fpp':6,\n",
    "        'normal-duo':7,\n",
    "        'normal-duo-fpp':8,\n",
    "        'normal-solo':9,\n",
    "        'normal-solo-fpp':10,\n",
    "        'normal-squad':11,\n",
    "        'normal-squad-fpp':12,\n",
    "        'crashfpp':13,\n",
    "        'crashtpp':14,\n",
    "        'flarefpp':15,\n",
    "        'flaretpp':16\n",
    "        })\n",
    "    train_OE = reduce_mem_usage(train_OE)\n",
    "    return train_OE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b931324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.255084Z",
     "start_time": "2022-06-16T00:41:45.251169Z"
    }
   },
   "outputs": [],
   "source": [
    "# optuna RandomForest\n",
    "def optimizer_RF(trial, X, y, K):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 8, 30)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", ['auto', 'sqrt', 'log2'])\n",
    "    evaluation_metric = mean_absolute_error\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  max_features=max_features,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=0xC0FFEE)\n",
    "    \n",
    "    folds = KFold(n_splits=K)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in folds.split(X, y):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        score = evaluation_metric(y_val, preds)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f74832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:41:45.261579Z",
     "start_time": "2022-06-16T00:41:45.257481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optuna LightGBM\n",
    "def optimizer_LGBM(trial, X, y, K):\n",
    "    import os\n",
    "    param = {\n",
    "        'objective': 'regression', # 회귀\n",
    "        'verbose': 0,\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 20),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
    "        #\"device\" : 'gpu'\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**param, n_jobs=os.cpu_count())\n",
    "    evaluation_metric = mean_absolute_error\n",
    "    \n",
    "    folds = KFold(n_splits=K)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in folds.split(X, y):\n",
    "        \n",
    "        # X_train,X_val = X[train_idx],X[val_idx]\n",
    "        # y_train,y_val = y[train_idx],y[val_idx]\n",
    "        \n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=25)\n",
    "        preds = model.predict(X_val)\n",
    "        score = evaluation_metric(y_val, preds)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e6c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropIdx(df, idx) :\n",
    "    df.drop(index=idx, inplace=True)\n",
    "    dropIdx.dpIdx_sum +=len(idx)\n",
    "    return df\n",
    "dropIdx.dpIdx_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39725ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropOutlier (df):\n",
    "    df = df.dropna(axis=0)\n",
    "    def dropIdx(df, idx) :\n",
    "        df.drop(index=idx, inplace=True)\n",
    "        dropIdx.dpIdx_sum +=len(idx)\n",
    "        return df\n",
    "    dropIdx.dpIdx_sum = 0\n",
    "\n",
    "    print(\"Pre-Processing...\")\n",
    "    for i in df.columns.to_list() :\n",
    "        df.drop(index=df[df[i].isnull()==True].index, inplace=True)\n",
    "        \n",
    "    print(\"Droping Outliers...\")\n",
    "\n",
    "    vip_features = [\"assists\",\"boosts\",\"DBNOs\",\"heals\",\"kills\",\"killStreaks\",\"walkDistance\", \"revives\", \"roadKills\", \"vehicleDestroys\"]\n",
    "\n",
    "    group = df.groupby('groupId').count()\n",
    "    df = dropIdx(df, df[df.groupId.isin(group[group[\"Id\"]>group[\"Id\"].quantile(0.9999)].index)==True].index) #수치고려 가능\n",
    "\n",
    "    for col in (vip_features + [\"damageDealt\",\"longestKill\", \"rideDistance\", \"swimDistance\",\"weaponsAcquired\", \"matchDuration\"]):\n",
    "        df = dropIdx(df, df[df[col]>df[col].quantile(0.999)].index)\n",
    "    \n",
    "    for col in vip_features:\n",
    "        df = dropIdx(df, df[df[\"walkDistance\"]<df[col]].index)\n",
    "\n",
    "    df = dropIdx(df, df[df.groupby('matchId')['kills'].transform('max')  > df.groupby('matchId')['Id'].transform('count')  ].index)\n",
    "    df = dropIdx(df, df[(df['rideDistance']==0) & (df['roadKills']>0)  ].index)\n",
    "\n",
    "    #edge case\n",
    "    df.loc[(df.maxPlace>1)&(df.numGroups==1), \"maxPlace\"] = 1\n",
    "\n",
    "    print(f\"{dropIdx.dpIdx_sum} Columns has deleted!\") \n",
    "\n",
    "    del vip_features, group      \n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89695e",
   "metadata": {},
   "source": [
    "\"assists\",\n",
    "\"boosts\",\"DBNOs\",\n",
    "\"heals\",\"kills\",\n",
    "\"killStreaks\",\"walkDistance\", \n",
    "\"revives\", \"roadKills\", \n",
    "\"vehicleDestroys\",\"damageDealt\",\n",
    "\"longestKill\", \"rideDistance\", \n",
    "\"swimDistance\",\"weaponsAcquired\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc86e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropOutlier (df):\n",
    "    df = df.dropna(axis=0)\n",
    "    def dropIdx(df, idx) :\n",
    "        df.drop(index=idx, inplace=True)\n",
    "        dropIdx.dpIdx_sum +=len(idx)\n",
    "        return df\n",
    "    dropIdx.dpIdx_sum = 0\n",
    "\n",
    "    print(\"Pre-Processing...\")\n",
    "    for i in df.columns.to_list() :\n",
    "        df.drop(index=df[df[i].isnull()==True].index, inplace=True)\n",
    "        \n",
    "    print(\"Droping Outliers...\")\n",
    "\n",
    "    vip_features = [\"assists\",\"boosts\",\"DBNOs\",\"heals\",\"kills\",\"killStreaks\",\"walkDistance\", \"revives\", \"roadKills\", \"vehicleDestroys\"]\n",
    "\n",
    "    group = df.groupby('groupId').count()\n",
    "    df = dropIdx(df, df[df.groupId.isin(group[group[\"Id\"]>group[\"Id\"].quantile(0.9999)].index)==True].index) #수치고려 가능\n",
    "\n",
    "    for col in (vip_features + [\"damageDealt\",\"longestKill\", \"rideDistance\", \"swimDistance\",\"weaponsAcquired\", \"matchDuration\"]):\n",
    "        df = dropIdx(df, df[df[col]>df[col].quantile(0.999)].index)\n",
    "    \n",
    "    for col in vip_features:\n",
    "        df = dropIdx(df, df[df[\"walkDistance\"]<df[col]].index)\n",
    "\n",
    "    df = dropIdx(df, df[df.groupby('matchId')['kills'].transform('max')  > df.groupby('matchId')['Id'].transform('count')  ].index)\n",
    "    df = dropIdx(df, df[(df['rideDistance']==0) & (df['roadKills']>0)  ].index)\n",
    "\n",
    "    #edge case\n",
    "    df.loc[(df.maxPlace>1)&(df.numGroups==1), \"maxPlace\"] = 1\n",
    "\n",
    "    print(f\"{dropIdx.dpIdx_sum} Columns has deleted!\") \n",
    "\n",
    "    del vip_features, group      \n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d207d075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T01:07:53.579365Z",
     "start_time": "2022-06-16T01:07:53.566897Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_enginnering(df):\n",
    "    # create columns\n",
    "    print(\"Making columns...\")\n",
    "    stat_feature = [\"assists\",\"boosts\",\"DBNOs\",\"heals\",\"kills\",\"killStreaks\",\"walkDistance\", \"revives\", \"roadKills\", \"vehicleDestroys\",\"damageDealt\",\"longestKill\", \"rideDistance\", \"swimDistance\",\"weaponsAcquired\"]\n",
    "    stat_list = [\"max\",\"mean\",\"median\",\"min\"]\n",
    "    for col in stat_feature :\n",
    "        for stat in stat_list:\n",
    "            df[f\"{col}_{stat}\"] = df.groupby(\"groupId\")[col].transform(stat)\n",
    "            df[f\"{col}_{stat}_Place\"] = df.groupby(\"matchId\")[f\"{col}_{stat}\"].transform('rank', ascending=False)\n",
    "    print(len(stat_feature)*len(stat_list)+1, f\"columns Made! now {len(df.columns)}column in DF.\")\n",
    "    \n",
    "    # create kiilRank using matchId, kills \n",
    "    df[\"killRank\"] = df.groupby(\"matchId\")[\"kills\"].rank(\"dense\", ascending=False)\n",
    "    \n",
    "    # drop unnecessary columns \n",
    "    print('Dropping columns...')\n",
    "    df = df.drop([\"Id\", \"groupId\",\"matchId\"], axis=1)\n",
    "    df = ordinal_encoding(df)\n",
    "    df = df.drop(['killPlace'], axis=1)\n",
    "    df = df.drop(['damageDealt'], axis=1)\n",
    "    df = df.drop(['numGroups'], axis=1)\n",
    "    df = df.drop(['killPoints','rankPoints','winPoints'], axis=1)\n",
    "    \n",
    "    print(len(df.columns), \"columns in df\")    \n",
    "    reduce_mem_usage(df)\n",
    "    del stat_feature\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009cb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(df,n):\n",
    "    idx = sorted(np.random.permutation(len(df))[:n])\n",
    "    return df.iloc[idx].copy()\n",
    "    n = len(train)  // 10\n",
    "    df_sample = sampling(train, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d06552",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034ddffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ordinal_encoding(train)\n",
    "test = ordinal_encoding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f8f57b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:42:17.811183Z",
     "start_time": "2022-06-16T00:42:14.637199Z"
    }
   },
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4187e70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T00:42:21.697352Z",
     "start_time": "2022-06-16T00:42:19.610871Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0)\n",
    "test = test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad58cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "groupId            0\n",
       "matchId            0\n",
       "assists            0\n",
       "boosts             0\n",
       "damageDealt        0\n",
       "DBNOs              0\n",
       "headshotKills      0\n",
       "heals              0\n",
       "killPlace          0\n",
       "killPoints         0\n",
       "kills              0\n",
       "killStreaks        0\n",
       "longestKill        0\n",
       "matchDuration      0\n",
       "matchType          0\n",
       "maxPlace           0\n",
       "numGroups          0\n",
       "rankPoints         0\n",
       "revives            0\n",
       "rideDistance       0\n",
       "roadKills          0\n",
       "swimDistance       0\n",
       "teamKills          0\n",
       "vehicleDestroys    0\n",
       "walkDistance       0\n",
       "weaponsAcquired    0\n",
       "winPoints          0\n",
       "winPlacePerc       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a396c",
   "metadata": {},
   "source": [
    "## Simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8be5b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T01:11:29.958221Z",
     "start_time": "2022-06-16T01:07:57.402482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making columns...\n",
      "61 columns Made! now 149column in DF.\n",
      "Dropping columns...\n",
      "141 columns in df\n"
     ]
    }
   ],
   "source": [
    "train = feature_enginnering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d745bca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T01:11:29.962968Z",
     "start_time": "2022-06-16T01:11:29.960304Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b22e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['winPlacePerc']\n",
    "features = train.drop(['winPlacePerc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc655d",
   "metadata": {},
   "source": [
    "no parameter tunings learn: 0.0767996"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9c2e8",
   "metadata": {},
   "source": [
    "- Linear 0.0661\n",
    "- XGB 0.0584\n",
    "- LGBM  0.0599\n",
    "- CB  999:\tlearn: 0.0767948\n",
    "\n",
    "- cb iterations=2, depth=2, learning_rate=1, loss_fuction='MAE' 1:\tlearn: 0.1097024\n",
    "- cb iterations=2, learning_rate=1, loss_fuction='MAE' 1:\tlearn: 0.0842670\n",
    "- cb iterations=2, learning_rate=10, loss_funtion=\"MAE\" 1:\tlearn: 21.6615617\n",
    "ㄴ learning rate is greater than 1. You probably need to decrease learning rate.\n",
    "- iterations=2, depth=10, learning_rate=1, loss_function='MAE' 1:\tlearn: 0.0760201\n",
    "- iterations=2, depth=20, learning_rate=1, loss_function='MAE' 1:\tCatBoostError : Maximum tree depth is 16\n",
    "- iterations=2, depth=16, learning_rate=1, loss_function='MAE' learn: 0.0701635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f54fd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllModels_mae(target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fba9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\t train=0.0661, val=0.0661\n"
     ]
    }
   ],
   "source": [
    "Linear_training_mae(target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c62147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\t\t train=0.1045, val=   0\n"
     ]
    }
   ],
   "source": [
    "Lasso_training_mae(target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac830d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making columns...\n",
      "61 columns Made! now 149column in DF.\n",
      "Dropping columns...\n",
      "140 columns in df\n"
     ]
    }
   ],
   "source": [
    "test = feature_enginnering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f300b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4446965 entries, 0 to 4446965\n",
      "Columns: 141 entries, assists to killRank\n",
      "dtypes: float16(106), int16(4), int8(31)\n",
      "memory usage: 1.1 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1934174 entries, 0 to 1934173\n",
      "Columns: 149 entries, Id to killRank\n",
      "dtypes: float16(25), float64(81), int16(7), int8(32), object(4)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aa25c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\t\t train=0.1045, val=   0\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "model = Lasso().fit(train_X,train_y)\n",
    "pred_train2 = model.predict(train_X)\n",
    "pred_val2 = model.predict(val_X)\n",
    "mae_train2 = mean_absolute_error(train_y, pred_train2)\n",
    "mae_val2 = mean_absolute_error(val_y, pred_val2)\n",
    "print(\"Lasso\\t\\t train=%.4f, val=%4.f\" % (mae_train2, mae_val2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "507890b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X, test_X, train_y, test_y = train_test_split(features, target, test_size=0.2, random_state=1511)\n",
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12538d",
   "metadata": {},
   "source": [
    "from sklearn.\n",
    "\n",
    "print(\"---------- Lasso ---------\")\n",
    "print('MSE in training: %.4f' % mean_squared_error(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2683a",
   "metadata": {},
   "source": [
    "1. 함수 수정\n",
    "2. catboost (hyper parameter tuning)\n",
    "3. best model test -> sumission -> 제출\n",
    "4. ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml-modeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "389aa9374f4d36b29366a128ce621c520da570e8b811567a5da792b5e3c43ec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
